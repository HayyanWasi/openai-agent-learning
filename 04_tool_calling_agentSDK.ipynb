{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gtNTLZx4FnwckRbn-WMqH5__DQ-mRQOC",
      "authorship_tag": "ABX9TyNbWYmafn5bSQtQ9QYtzoyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayyanWasi/openai-agent-learning/blob/main/04_tool_calling_agentSDK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Tool Calling**"
      ],
      "metadata": {
        "id": "XQtEqeDnu0O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tool calling are components of sdk that allow agents to perform actions such as web searching file searching interacting with other APIs or using a computer"
      ],
      "metadata": {
        "id": "st_7nIffe055"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BASIC AGENT STRUCTURE**"
      ],
      "metadata": {
        "id": "xxfhprG6hOKs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c9VmSxxf95i5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d761655f-f88c-4e73-b44e-490a066216e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/680.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m680.9/680.9 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents openai google-generativeai openai-agents python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "2ZaG_qi-ownC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "\n",
        "from agents.run import RunConfig\n",
        "\n",
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if not gemini_api_key:\n",
        "  raise ValueError(\"GEMINI_API_KEY not found in userdata\")\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key = gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta\",\n",
        ")\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model = \"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=(True)\n",
        ")"
      ],
      "metadata": {
        "id": "j9Ew2MCYo6Uv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HOSTED TOOLS**\n",
        "> They are built in functions\n",
        "> **They are of 3 types**\n",
        "\n",
        "1. WebSearchTool-allow agent to   perform  live web searching\n",
        "\n",
        "2. FileSearchTool-for taking information from vector stores\n",
        "\n",
        "3. ComputerTool-enable automation task on your computer\n"
      ],
      "metadata": {
        "id": "G9ckVrSLfLJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tool name is name of function\n",
        "descripton for agent is comes from docstring\n",
        "sechema is automatically generated from arguments\n",
        "description of input is also comes from docstring"
      ],
      "metadata": {
        "id": "_Auks8NAcUn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import function_tool\n",
        "\n",
        "@function_tool\n",
        "def get_weather(city:str)-> str:           #function name is taken as tool name\n",
        "  print(f\"getting weather for {city}\")     #description comes from docstrings\n",
        "  return f\"the weather in {city} is sunny\" #schema is generated from arguments\n",
        "\n",
        "\n",
        "@function_tool\n",
        "def get_temperature(city:str)->str:\n",
        "  print(f\"getting temperature for {city}\")\n",
        "  return \"70 degrees\"\n",
        "\n",
        "agent = Agent(\n",
        "      name=\"weather agent\",\n",
        "      instructions =\"you are the local weather agent.YOur are given a city and you need to tell the weather and temperature.\",\n",
        "      tools=[get_weather, get_temperature], #this registers function as a tool.Agent will automaticlly decide when to call this tool based on user's query this is part of tool calling mechanism in agent SDK\n",
        "      model = model\n",
        "  )\n",
        "\n",
        "result = await Runner.run(agent,\"how old is the moon\")\n",
        "print(result.final_output)\n",
        "\n"
      ],
      "metadata": {
        "id": "YMNDdUXl2ZVK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd82e54-499a-4dbe-da9d-60b04ccc16f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am sorry, I cannot fulfill this request. I can only get weather and temperature information for a city.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **WEB SEARCH TOOL**\n",
        "used for web searching"
      ],
      "metadata": {
        "id": "ikvH0cATxqXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from agents import WebSearchTool, Agent, Runner\n",
        "\n",
        "# # Create an agent that uses the hosted WebSearchTool\n",
        "# news_agent = Agent(\n",
        "#     name=\"News Reporter\",\n",
        "#     instructions=\"You're a news reporter. Find recent news articles about Pakistan politics.\",\n",
        "#     tools=[WebSearchTool()],\n",
        "#     model=model\n",
        "# )\n",
        "\n",
        "# # Run the agent with a query\n",
        "# news_result = await Runner.run(news_agent, \"Find recent news about Pakistan politics\")\n",
        "# print(news_result.final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SS-ehciFwg4g",
        "outputId": "02baec37-2c6d-407b-d254-62f9306b3d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UserError",
          "evalue": "Hosted tools are not supported with the ChatCompletions API. Got tool type: <class 'agents.tool.WebSearchTool'>, tool: WebSearchTool(user_location=None, search_context_size='medium')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUserError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-0fd51c067ed8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run the agent with a query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mnews_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Find recent news about Pakistan politics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/run.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mcurrent_turn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                         input_guardrail_results, turn_result = await asyncio.gather(\n\u001b[0m\u001b[1;32m    219\u001b[0m                             cls._run_input_guardrails(\n\u001b[1;32m    220\u001b[0m                                 \u001b[0mstarting_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/run.py\u001b[0m in \u001b[0;36m_run_single_turn\u001b[0;34m(cls, agent, all_tools, original_input, generated_items, hooks, context_wrapper, run_config, should_run_agent_start_hooks, tool_use_tracker, previous_response_id)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenerated_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_input_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenerated_item\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerated_items\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m         new_response = await cls._get_new_response(\n\u001b[0m\u001b[1;32m    761\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/run.py\u001b[0m in \u001b[0;36m_get_new_response\u001b[0;34m(cls, agent, system_prompt, input, output_schema, all_tools, handoffs, context_wrapper, run_config, tool_use_tracker, previous_response_id)\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mmodel_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunImpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_reset_tool_choice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_use_tracker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         new_response = await model.get_response(\n\u001b[0m\u001b[1;32m    920\u001b[0m             \u001b[0msystem_instructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msystem_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/models/openai_chatcompletions.py\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, tracing, previous_response_id)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mdisabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_disabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         ) as span_generation:\n\u001b[0;32m---> 61\u001b[0;31m             response = await self._fetch_response(\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0msystem_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/models/openai_chatcompletions.py\u001b[0m in \u001b[0;36m_fetch_response\u001b[0;34m(self, system_instructions, input, model_settings, tools, output_schema, handoffs, span, tracing, stream)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mresponse_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mconverted_tools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_to_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtools\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandoff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandoffs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/models/openai_chatcompletions.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mresponse_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mconverted_tools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtool_to_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtool\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtools\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandoff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandoffs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/agents/models/chatcmpl_converter.py\u001b[0m in \u001b[0;36mtool_to_openai\u001b[0;34m(cls, tool)\u001b[0m\n\u001b[1;32m    450\u001b[0m             }\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         raise UserError(\n\u001b[0m\u001b[1;32m    453\u001b[0m             \u001b[0;34mf\"Hosted tools are not supported with the ChatCompletions API. Got tool type: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0;34mf\"{type(tool)}, tool: {tool}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUserError\u001b[0m: Hosted tools are not supported with the ChatCompletions API. Got tool type: <class 'agents.tool.WebSearchTool'>, tool: WebSearchTool(user_location=None, search_context_size='medium')"
          ]
        }
      ]
    }
  ]
}