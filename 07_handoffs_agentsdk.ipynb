{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI9URcWVE6jJK0OJcKGNTM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HayyanWasi/openai-agent-learning/blob/main/07_handoffs_agentsdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4Bp8N3Q__Mc",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install openai google-generativeai openai-agents python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "pSSpNAWbBP0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agents import Agent, Runner, AsyncOpenAI, set_default_openai_client, set_tracing_disabled, OpenAIChatCompletionsModel, RunConfig\n",
        "import os\n",
        "\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "set_tracing_disabled(True)\n",
        "\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\",\n",
        ")\n",
        "\n",
        "\n",
        "set_default_openai_client(external_client)\n",
        "\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"models/gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "config = RunConfig(\n",
        "    model=model,\n",
        "    model_provider=external_client,\n",
        "    tracing_disabled=True\n",
        "    )\n"
      ],
      "metadata": {
        "id": "WufQil6dBSR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class Tutorial(BaseModel):\n",
        "  outline:str\n",
        "  tutorial:str\n",
        "\n",
        "\n",
        "\n",
        "#model which is used by the agent to generate tutorial\n",
        "tutorial_genrator = Agent(\n",
        "    name=\"Tutorial Generator\",\n",
        "    # handsoff_description = \"this is used for making tutorials based on outline builder\", #use for precision in decision making\n",
        "    instructions=\"your are You are TutorialGPT, an expert in generating clear, structured, and engaging tutorials on any topic. Your job is to create high-quality step-by-step tutorials tailored to the target audience’s skill level (beginner, intermediate, or advanced).\",\n",
        "    model=model,\n",
        "    output_type=Tutorial\n",
        ")\n",
        "#used to generate outline after completing its work it can handoff its control to tutorial_generator to make tutorial around the outline after giving handoff an agent can not be return bacl\n",
        "outline_builder= Agent(\n",
        "    name=\"outline border\",\n",
        "    instructions=(\"You are OutlineGPT, an expert assistant that creates well-structured, logical outlines for programming tutorials.\"\n",
        "    \"Your task is to generate detailed tutorial outlines on any programming topic (language, framework, tool, or concept) based on the user’s input.\"),\n",
        "    handoffs=[tutorial_genrator], #using handoff\n",
        "    model=model\n",
        ")\n",
        "tutorial_response = await Runner.run(outline_builder,\"i want to learn  loops in java\")\n",
        "print(tutorial_response.final_output)"
      ],
      "metadata": {
        "id": "ilSnGAPHBcBY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from agents import function_tool\n",
        "from agents import RunContextWrapper, handoff\n",
        "from google.generativeai import configure, GenerativeModel\n",
        "\n",
        "class ManageEscalation(BaseModel):\n",
        "    issue: str\n",
        "    why: str\n",
        "\n",
        "@function_tool\n",
        "def create_ticket(issue:str):\n",
        "  \"\"\"\n",
        "  create a ticket in the system for an issue to be resolved\n",
        "  \"\"\"\n",
        "  print(f\"Creating ticket for {issue}\")\n",
        "  return \"Ticket created ID: 12345\"\n",
        "\n",
        "\n",
        "manager_agent = Agent(\n",
        "    name=\"Manager\",\n",
        "    handoff_description=\"Handles esalated issued that require managerial attention\",\n",
        "    instructions=\"You handle escalated customer issue that the inital customer service agent could not resolve you will recieve the issue and the reason for escalation. If the issue cannot be immediately resolved for the customer, create a ticket in the system and inform the customer\",\n",
        "    tools=[create_ticket],\n",
        "    model=model\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "def on_manager_handoff(stx: RunContextWrapper[None], input:ManageEscalation):\n",
        "  print(\"Escalating to manager agent:\", input.issue)\n",
        "  print(\"Reason for escalation:\", input.why)\n",
        "\n",
        "customer_service_agent = Agent(\n",
        "    name=\"Customer  Service\",\n",
        "    instructions=\"You assist customers with general inquiries and the basic troubleshooting.\"+\n",
        "    \"if the issue cannot be resolved , escalate it to the manager along with the reason why you cannot fix the issue yourself\",\n",
        "    handoffs=[handoff(agent=manager_agent,\n",
        "                      input_type=ManageEscalation,\n",
        "                      on_handoff=on_manager_handoff\n",
        "     )],\n",
        "    model=model\n",
        "\n",
        ")\n",
        "result = await Runner.run(customer_service_agent, \"I want a refund but your system won't let process it. the website is just blank for me.\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPEdil_3vVyZ",
        "outputId": "8832bc8f-712c-4a0d-8c9d-e309f0dd1c22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escalating to manager agent: refund request and website is blank\n",
            "Reason for escalation: the system won't let the user process the refund and the website is blank\n",
            "Creating ticket for refund request and website is blank\n",
            "OK. I have created a ticket for you with ID 12345. We will investigate the issue and process your refund as soon as possible.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}